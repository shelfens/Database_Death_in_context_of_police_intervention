{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5ebb0e0",
   "metadata": {},
   "source": [
    "# Scraping Lead Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import relativedelta\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327abf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_start = \"https://www.letemps.ch/archive/\"\n",
    "data = []\n",
    "missed_data = []\n",
    "links = pd.read_excel(\"../databases/Pipeline2_keywords.xlsx\")\n",
    "links = links['Link'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce016a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Lead Posts\n",
    "for i in links:\n",
    "    url = i\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "    success = False\n",
    "    retries = 0\n",
    "    max_retries = 5 \n",
    "\n",
    "    while not success and retries < max_retries:\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            \n",
    "            if response.status_code == 429:\n",
    "                print(f\"Rate limited (429) on {url}, retrying...\")\n",
    "                time.sleep(1)\n",
    "                retries += 1\n",
    "                continue\n",
    "\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            post_lead = soup.find(class_=\"post__lead\")\n",
    "            if post_lead:\n",
    "                articles = post_lead.select(\"p\")\n",
    "                for article in articles:\n",
    "                    lead_post = article.get_text(strip=True)\n",
    "\n",
    "                    data.append({\"Title\": lead_post, \"Link\": i})\n",
    "            else:\n",
    "                print(f\"No 'lead_post' section found on {url}\")\n",
    "\n",
    "            success = True  # Success: exit loop\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching {url}: {e}, retrying...\")\n",
    "            time.sleep(1)\n",
    "            retries += 1\n",
    "\n",
    "    if not success:\n",
    "        print(f\"Failed after retries: {url}\")\n",
    "        missed_data.append(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bef259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data, columns= [\"Title\", \"Link\"])\n",
    "missed_data = pd.DataFrame(data=missed_data, columns= [\"Link\"])\n",
    "\n",
    "df.to_excel(\"databases/Pipeline2_toapply.xlsx\",sheet_name='Le_Temps')  # Pipeline1_LeadPosts_Le_Temps.xlsx for Pipeline 1\n",
    "#missed_data.to_excel(\"shelfens/Missed_data_LP2.xlsx\", sheet_name=\"Titles\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
